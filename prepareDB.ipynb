{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy.sql\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "from werkzeug.security import generate_password_hash, check_password_hash\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import psycopg2\n",
    "import geopandas\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .gpx calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts gpx file to pandas dataframe\n",
    "def make_df(f):\n",
    "    gpx_file = open(f, 'r') #open gpx file\n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "\n",
    "    data = gpx.tracks[0].segments[0].points\n",
    "\n",
    "    nonext = pd.DataFrame(columns=['lon', 'lat', 'alt', 'time']) #initialize empty df\n",
    "\n",
    "    for point in data: #reformat time variable\n",
    "        point.time = str(point.time).split('+')[0]\n",
    "\n",
    "    for point in data: #put non-extension data into df\n",
    "        nonext = nonext.append({'lon': point.longitude, \n",
    "                    'lat' : point.latitude, \n",
    "                    'alt' : point.elevation, \n",
    "                    'time' : point.time,\n",
    "                   }, \n",
    "                   ignore_index=True)\n",
    "\n",
    "\n",
    "    with open(f, 'r') as f2:\n",
    "        file_text = f2.read().replace('\\n', '')\n",
    "\n",
    "    #format of gpx file depends on presence of atemp, hr, and cad\n",
    "    if ('gpxtpx:atemp' in file_text and 'gpxtpx:hr' in file_text and 'gpxtpx:cad' in file_text):\n",
    "        ext = pd.DataFrame(columns=['atemp', 'hr', 'cad'])\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            ext = ext.append({\n",
    "                'atemp': int(gpx.tracks[0].segments[0].points[i].extensions[0].getchildren()[0].text),\n",
    "                'hr': int(gpx.tracks[0].segments[0].points[i].extensions[0].getchildren()[1].text),\n",
    "                'cad': int(gpx.tracks[0].segments[0].points[i].extensions[0].getchildren()[2].text)\n",
    "            },\n",
    "            ignore_index=True)\n",
    "    elif('gpxtpx:hr' in file_text and 'gpxtpx:cad' in file_text):\n",
    "        ext = pd.DataFrame(columns=['hr', 'cad'])\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            ext = ext.append({\n",
    "                'hr': int(gpx.tracks[0].segments[0].points[i].extensions[0].getchildren()[0].text),\n",
    "                'cad': int(gpx.tracks[0].segments[0].points[i].extensions[0].getchildren()[1].text)\n",
    "            },\n",
    "            ignore_index=True)\n",
    "    else:\n",
    "        ext = pd.DataFrame()\n",
    "\n",
    "    if (ext.empty):\n",
    "        df = nonext\n",
    "    else:\n",
    "        df = nonext.join(ext)\n",
    "\n",
    "    df['time'] = df['time'].astype('datetime64')\n",
    "    df['total_gain'] = 0\n",
    "    df['total_dist'] = 0\n",
    "    df['pace'] = 0\n",
    "\n",
    "    for i in range(1, len(df)): #compute rolling altitude gain\n",
    "        currentAlt = df.loc[i, 'alt']\n",
    "        lastAlt = df.loc[i-1, 'alt']\n",
    "        altDiff = currentAlt - lastAlt\n",
    "    \n",
    "        if (altDiff > 0):\n",
    "            df.loc[i, 'total_gain'] = df.loc[i-1, 'total_gain'] + altDiff\n",
    "        else:\n",
    "            df.loc[i, 'total_gain'] = df.loc[i-1, 'total_gain'] \n",
    "\n",
    "    for i in range(1, len(df)): #compute rolling total distance\n",
    "        currentPos = (df.loc[i, 'lat'], df.loc[i, 'lon'])\n",
    "        lastPos = (df.loc[i-1, 'lat'], df.loc[i-1, 'lon'])\n",
    "        distTrav = geopy.distance.distance(currentPos, lastPos).mi\n",
    "        df.loc[i, 'total_dist'] = df.loc[i-1, 'total_dist'] + distTrav\n",
    "\n",
    "    for i in range(1, len(df)): #compute rolling current pace\n",
    "        currentPos = (df.loc[i, 'lat'], df.loc[i, 'lon'])\n",
    "        lastPos = (df.loc[i-1, 'lat'], df.loc[i-1, 'lon'])\n",
    "        distTrav = geopy.distance.distance(currentPos, lastPos).mi\n",
    "        \n",
    "        currentTime = df.loc[i, 'time']\n",
    "        lastTime = df.loc[i-1, 'time']\n",
    "        timeDiff = pd.Timedelta(currentTime - lastTime).seconds\n",
    "    \n",
    "        if (distTrav == 0):\n",
    "            df.loc[i, 'pace'] = 0\n",
    "        else:\n",
    "            df.loc[i, 'pace'] = (timeDiff / 60) / distTrav   \n",
    "        \n",
    "    return(df)\n",
    "\n",
    "\n",
    "#adds mean hr and mean pace to data for 1st and 2nd half of run\n",
    "def split_vis(df, data):\n",
    "    midpoint = df['total_dist'].iloc[-1] / 2\n",
    "\n",
    "    split1_meanpace = round(df[df['total_dist'] < midpoint]['pace'].mean(),2)\n",
    "    split2_meanpace = round(df[df['total_dist'] > midpoint]['pace'].mean(),2)\n",
    "    splits_pace_python = [{'Split': '1st Half', 'Pace': split1_meanpace}, {'Split': '2nd Half', 'Pace': split2_meanpace}]\n",
    "    splits_pace_json = json.dumps(splits_pace_python)\n",
    "    data['splits_pace'] = splits_pace_json\n",
    "\n",
    "    split1_meanhr = round(df[df['total_dist'] < midpoint]['hr'].mean(),2)\n",
    "    split2_meanhr = round(df[df['total_dist'] > midpoint]['hr'].mean(),2)\n",
    "    splits_hr_python = [{'Split': '1st Half', 'HR': split1_meanhr}, {'Split': '2nd Half', 'HR': split2_meanhr}]\n",
    "    splits_hr_json = json.dumps(splits_hr_python)\n",
    "    data['splits_hr'] = splits_hr_json\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#adds coordinates to data\n",
    "def map_vis(df, data):\n",
    "    lat_max = df['lat'].max()\n",
    "    lon_max = df['lon'].max()\n",
    "\n",
    "    lat_min = df['lat'].min()\n",
    "    lon_min = df['lon'].min()\n",
    "\n",
    "    lat_avg = (lat_max + lat_min) / 2\n",
    "    lon_avg = (lon_max + lon_min) / 2\n",
    "\n",
    "    map_center_python = [{'Lat': lat_avg, 'Lon': lon_avg}]\n",
    "    map_center_json = json.dumps(map_center_python)\n",
    "\n",
    "    data['map_center'] = map_center_json\n",
    "\n",
    "    coord_df = df[['lon', 'lat']].copy()\n",
    "\n",
    "    coords = coord_df.values.tolist()\n",
    "    data['coord'] = coords\n",
    "    data['start'] = coords[0]\n",
    "    data['finish'] = coords[-1]\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#adds dist, alt, hr, and pace to data\n",
    "def alt_hr_pace_vis(df, data):\n",
    "    alt_hr_pace_json = df[['total_dist', 'alt', 'hr', 'pace']].to_json(orient='records')\n",
    "    data['alt_hr_pace'] = alt_hr_pace_json\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#adds average pace, hr, total distance, total time, and total gain to data\n",
    "def summary_stats(df, data):\n",
    "    avg_pace = round(df['pace'].mean(),2)\n",
    "    data['avg_pace'] = avg_pace\n",
    "\n",
    "    avg_hr = round(df['hr'].mean(),2)\n",
    "    data['avg_hr'] = avg_hr\n",
    "\n",
    "    total_distance = round(df['total_dist'].max(),2)\n",
    "    data['total_distance'] = total_distance\n",
    "\n",
    "    total_time_string = str(df['time'].max() - df['time'].min()).split('days')[1].strip()\n",
    "    data['total_time'] = total_time_string\n",
    "\n",
    "    total_gain = round(df['total_gain'].max(),2)\n",
    "    data['total_gain'] = total_gain\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#add pace distribution to data\n",
    "def pace_dist(df, data):\n",
    "    min_pace = df['pace'].min()\n",
    "    max_pace = df['pace'].max()\n",
    "\n",
    "    min_pace_round = round(min_pace*2)/2\n",
    "    max_pace_round = round(max_pace*2)/2\n",
    "\n",
    "    if min_pace_round < 0.5:\n",
    "        min_pace_round = 0.0\n",
    "    else:\n",
    "        min_pace_round = min_pace_round - 0.5\n",
    "\n",
    "    pace_df = pd.DataFrame(columns=['pace', 'count'])\n",
    "\n",
    "    total_len = len(df)\n",
    "\n",
    "    for i in np.arange(min_pace_round, max_pace_round + 0.51, 0.5):\n",
    "        bucket_length = len(df[(df['pace'] >= i) & (df['pace'] < i + 0.5)])\n",
    "        if (bucket_length/total_len >= 0.05):\n",
    "            new_row = {'pace': str(i) +'-' + str(i+0.5), 'count':bucket_length}\n",
    "            pace_df = pace_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    pace_count_sum = pace_df['count'].sum()\n",
    "    pace_df['percentage'] = (pace_df['count'] / pace_count_sum) * 100\n",
    "    pace_df['percentage'] = pace_df['percentage'].astype('float').round(2)\n",
    "    pace_data_json = pace_df[['pace', 'percentage']].to_json(orient='records')\n",
    "\n",
    "    data['pace_dist'] = pace_data_json\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#adds hr distribution to data\n",
    "def hr_dist(df, data):\n",
    "    max_hr = df['hr'].max()\n",
    "\n",
    "    max_hr_round = int(math.ceil(max_hr / 10.0)) * 10\n",
    "\n",
    "    hr_df = pd.DataFrame(columns=['hr', 'count'])\n",
    "\n",
    "    total_len = len(df)\n",
    "\n",
    "    for i in range(0, max_hr_round, 10):\n",
    "        bucket_length = len(df[(df['hr'] >= i) & (df['hr'] < i + 10)])\n",
    "        if (bucket_length/total_len >= 0.05):\n",
    "            new_row = {'hr': str(i) +'-' + str(i+10), 'count':bucket_length}\n",
    "            hr_df = hr_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    hr_count_sum = hr_df['count'].sum()\n",
    "    hr_df['percentage'] = (hr_df['count'] / hr_count_sum) * 100\n",
    "    hr_df['percentage'] = hr_df['percentage'].astype('float').round(2)\n",
    "    hr_data_json = hr_df[['hr', 'percentage']].to_json(orient='records')\n",
    "\n",
    "    data['hr_dist'] = hr_data_json\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#calculates altitute change\n",
    "def getAltChange(alt_list):\n",
    "    change = 0\n",
    "    list_len = len(alt_list)\n",
    "    \n",
    "    for i in range(list_len):\n",
    "        if (i < list_len - 1):\n",
    "            change = change + alt_list[i + 1] - alt_list[i]  \n",
    "    return(change)\n",
    "\n",
    "\n",
    "#adds pace, hr, and alt by mile split to data\n",
    "def split_table(df, data):\n",
    "    max_dist = df['total_dist'].max()\n",
    "\n",
    "    splits_df = pd.DataFrame(columns=['split (mi)', 'pace (min/mi)', 'hr (bpm)', 'gain (m)'])\n",
    "\n",
    "    for i in np.arange(0, max_dist):\n",
    "        split = df[(df['total_dist'] >= i) & (df['total_dist'] < i + 1) ]\n",
    "        mile = i + 1\n",
    "        split_pace = split['pace'].mean()\n",
    "        split_hr = split['hr'].mean()\n",
    "        split_alt = getAltChange(split['alt'].to_list())\n",
    "        \n",
    "        if(mile > max_dist):\n",
    "            mile = max_dist - i\n",
    "        \n",
    "        new_row = {'split (mi)': mile, 'pace (min/mi)': split_pace, 'hr (bpm)': split_hr, 'gain (m)': split_alt}\n",
    "        splits_df = splits_df.append(new_row, ignore_index = True)\n",
    "        \n",
    "    splits_df = splits_df.round(2)\n",
    "\n",
    "    splits_data_json = splits_df.to_json(orient='records')\n",
    "    data['split_table'] = splits_data_json\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#takes .gpx file and returns data object\n",
    "def vis_fun(file):\n",
    "    df = make_df(file)\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    title = file.replace('.gpx','').replace('_',' ')\n",
    "    data['title'] = title\n",
    "    data['date'] = df['time'][0].date()\n",
    "\n",
    "    data = split_vis(df, data)\n",
    "    data = map_vis(df, data)\n",
    "    data = alt_hr_pace_vis(df, data)\n",
    "    data = summary_stats(df, data)\n",
    "    data = pace_dist(df, data)\n",
    "    data = hr_dist(df, data)\n",
    "    data = split_table(df, data)\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbuser='ltrgaknf'\n",
    "passwd = 'N0UBQC-McQo6SyHm5ex6jfXgL3ExvY0O' \n",
    "eng = create_engine('postgresql://{0}:{1}@otto.db.elephantsql.com:5432/ltrgaknf'.format(dbuser, passwd))\n",
    "con = eng.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create and populate users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create users table\n",
    "rs = con.execute('''\n",
    "DROP TABLE IF EXISTS users CASCADE;\n",
    "CREATE TABLE users\n",
    "    (\n",
    "    user_id bigserial PRIMARY KEY,\n",
    "    username varchar(64) UNIQUE NOT NULL,\n",
    "    password varchar(128) NOT NULL,\n",
    "    birth_date date NOT NULL CONSTRAINT check_age CHECK(DATE_PART('years', AGE(birth_date)) > 12),\n",
    "    coach_bool boolean DEFAULT False\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate users table\n",
    "\n",
    "#calculate days between for random birthdate\n",
    "early_date = datetime.date(1930, 1, 1) \n",
    "late_date = datetime.date(2002, 1, 1)\n",
    "days_between = (late_date - early_date).days\n",
    "\n",
    "#50 users\n",
    "for i in range(1, 51):\n",
    "    username = 'user' + str(i)\n",
    "    \n",
    "    password = 'password' + str(i)\n",
    "    password_hash = generate_password_hash(password)\n",
    "    \n",
    "    #random birthdate \n",
    "    random_days = random.randrange(days_between)\n",
    "    birth_date = early_date + datetime.timedelta(days=random_days)\n",
    "    \n",
    "    if(i % 10 == 0): #even values are coaches\n",
    "        coach_bool = True\n",
    "    else:\n",
    "        coach_bool = False\n",
    "    \n",
    "    row = {'username': username, 'password_hash': password_hash, 'birth_date': birth_date, 'coach_bool': coach_bool}\n",
    "    cmd = sqlalchemy.sql.text('''INSERT INTO users(username, password, birth_date, coach_bool)\\\n",
    "    VALUES (:username, :password_hash, :birth_date, :coach_bool)''')\n",
    "    con.execute(cmd, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trigger to check on updates that if user is no longer coach that records are removed from runner_has_coach\n",
    "rs = con.execute('''\n",
    "CREATE OR REPLACE FUNCTION coach_no_more()\n",
    "    RETURNS TRIGGER\n",
    "    AS $coach_no_more$\n",
    "    BEGIN\n",
    "        IF (SELECT COUNT(coach_user_id) FROM runner_has_coach JOIN users ON coach_user_id=user_id WHERE coach_bool=False)>0 THEN\n",
    "            DELETE FROM runner_has_coach WHERE coach_user_id IN (SELECT coach_user_id FROM runner_has_coach JOIN users ON coach_user_id=user_id WHERE coach_bool=False);\n",
    "        END IF;\n",
    "        \n",
    "        RETURN NEW;\n",
    "    END;\n",
    "$coach_no_more$ LANGUAGE PLPGSQL;\n",
    "''')\n",
    "\n",
    "rs = con.execute('''\n",
    "DROP TRIGGER IF EXISTS coach_no_more on users;\n",
    "CREATE TRIGGER coach_no_more AFTER UPDATE ON users\n",
    "    FOR EACH ROW EXECUTE FUNCTION coach_no_more();\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check 50 users added\n",
    "con.execute('''SELECT count(user_id)\n",
    "            FROM users''').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'user1', 'pbkdf2:sha256:50000$CC0xdf7O$e98b9e4e8e90ac121ec6aa0c0de07b2cbbbc67b3ffd45431f24d76befa8be093', datetime.date(1981, 4, 6), False),\n",
       " (2, 'user2', 'pbkdf2:sha256:50000$HE1MX65U$f623520ff9a60cfdfc4ef5fab2250b908f7933068e021268444a259f5c9e4bde', datetime.date(1932, 12, 3), False),\n",
       " (3, 'user3', 'pbkdf2:sha256:50000$cmJHiePa$549e5e749a63bf72fdf8ecc3bbd295f1b827cae80b83319c652e691a6d1b0c11', datetime.date(1968, 6, 23), False),\n",
       " (4, 'user4', 'pbkdf2:sha256:50000$gN8xH7tt$5da5fac6b4f458fb58621f491874f53e4836a1e5fc226ab4396a79cb2709fec3', datetime.date(1973, 4, 17), False),\n",
       " (5, 'user5', 'pbkdf2:sha256:50000$Cc8GYxyY$a4f978681fd3d545408343ca2c8133db5a0e78a146c490f008ac426a95ca90ae', datetime.date(1981, 11, 11), False)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 5 row\n",
    "con.execute('''SELECT *\n",
    "            FROM users\n",
    "            LIMIT 5''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create and populate runner_has_coach table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create runner_has_coach table\n",
    "rs = con.execute('''\n",
    "DROP TABLE IF EXISTS runner_has_coach;\n",
    "CREATE TABLE runner_has_coach\n",
    "    (\n",
    "    runner_user_id bigint,\n",
    "    coach_user_id bigint,\n",
    "    FOREIGN KEY (runner_user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (coach_user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trigger to check on inserts that user is coach and no duplicate inserts\n",
    "rs = con.execute('''\n",
    "CREATE OR REPLACE FUNCTION check_is_coach()\n",
    "    RETURNS TRIGGER\n",
    "    AS $check_is_coach$\n",
    "    BEGIN\n",
    "        IF (SELECT coach_bool FROM users WHERE user_id = NEW.coach_user_id)=False THEN\n",
    "            RAISE EXCEPTION 'user must be a coach';\n",
    "        END IF;\n",
    "        \n",
    "        IF (SELECT count(*) FROM runner_has_coach WHERE (NEW.runner_user_id = runner_user_id AND NEW.coach_user_id = coach_user_id)) > 0 THEN\n",
    "            RAISE EXCEPTION 'duplicate runner-coach set';\n",
    "        END IF;\n",
    "        \n",
    "        RETURN NEW;\n",
    "    END;\n",
    "$check_is_coach$ LANGUAGE PLPGSQL;\n",
    "''')\n",
    "\n",
    "rs = con.execute('''\n",
    "DROP TRIGGER IF EXISTS check_is_coach on runner_has_coach;\n",
    "CREATE TRIGGER check_is_coach BEFORE INSERT ON runner_has_coach\n",
    "    FOR EACH ROW EXECUTE FUNCTION check_is_coach();\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate runner_has_coach table\n",
    "for i in range(1, 51):\n",
    "    if(i % 10 == 0): #user_ids i % 10 == 0 are coaches \n",
    "        runner_count = random.randint(0, 9)\n",
    "        coach = i\n",
    "        runner = i\n",
    "        for j in range(runner_count): #coaches have 0-9 runners \n",
    "            runner = runner - 1\n",
    "            row = {'runner_user_id': runner, 'coach_user_id': coach}\n",
    "            cmd = sqlalchemy.sql.text('''INSERT INTO runner_has_coach(runner_user_id, coach_user_id)\\\n",
    "            VALUES (:runner_user_id, :coach_user_id)''')\n",
    "            con.execute(cmd, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29,)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of records in runner_has_coach\n",
    "con.execute('''SELECT COUNT(coach_user_id)\n",
    "            FROM runner_has_coach\n",
    "            ''').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 10), (8, 10), (7, 10), (6, 10), (5, 10)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 5 rows\n",
    "con.execute('''SELECT *\n",
    "            FROM runner_has_coach\n",
    "            LIMIT 5''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create and populate runs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create runs table\n",
    "rs = con.execute('''\n",
    "DROP TABLE IF EXISTS runs CASCADE;\n",
    "CREATE TABLE runs\n",
    "    (\n",
    "    run_id bigserial PRIMARY KEY,\n",
    "    runner_id bigint NOT NULL,\n",
    "    title varchar(64),\n",
    "    date date,\n",
    "    duration time,\n",
    "    distance real,\n",
    "    pace real,\n",
    "    hr real,\n",
    "    gain real,\n",
    "    start_coords real[],\n",
    "    finish_coords real[],\n",
    "    all_coords real[],\n",
    "    split_table json,\n",
    "    split_hr json,\n",
    "    split_pace json,\n",
    "    dist_hr json,\n",
    "    dist_pace json,\n",
    "    race_bool boolean DEFAULT False,\n",
    "    race_id bigint DEFAULT -1,\n",
    "    FOREIGN KEY (runner_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "CPU times: user 1min 52s, sys: 284 ms, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#create list of data to be inserted\n",
    "data_list = []\n",
    "directory = 'gpx_files'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".gpx\"): \n",
    "        data_list.append(vis_fun(os.path.join(directory, filename)))\n",
    "\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.17 s, sys: 311 ms, total: 5.49 s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#populate runs table\n",
    "\n",
    "for i in range(1, 51): #for each user\n",
    "    for j in range(len(data_list)): #for each run\n",
    "        run_count = random.randint(0, 2)\n",
    "        for k in range(run_count): #for a random number of runs each week\n",
    "            data_list[j]['runner_id'] = i\n",
    "\n",
    "            if(j % 2 == 0 and k == 0):\n",
    "                data_list[j]['race_bool'] = True\n",
    "                data_list[j]['race_id'] = j\n",
    "            else:\n",
    "                data_list[j]['race_bool'] = False\n",
    "                data_list[j]['race_id'] = -1\n",
    "\n",
    "            cmd = sqlalchemy.sql.text('''INSERT INTO runs(runner_id, title, date, duration, distance, pace, hr, gain, start_coords, finish_coords, all_coords, split_table, split_hr, split_pace, dist_hr, dist_pace, race_bool, race_id)\\\n",
    "            VALUES (:runner_id, :title, :date, :total_time, :total_distance, :avg_pace, :avg_hr, :total_gain, :start, :finish, :coord, :split_table, :splits_hr, :splits_pace, :hr_dist, :pace_dist, :race_bool, :race_id)''')\n",
    "            con.execute(cmd, data_list[j])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trigger to check on updates that if run is no longer a race that race_id is set to -1\n",
    "rs = con.execute('''\n",
    "CREATE OR REPLACE FUNCTION race_no_more()\n",
    "    RETURNS TRIGGER\n",
    "    AS $race_no_more$\n",
    "    BEGIN\n",
    "        IF (SELECT COUNT(race_bool) FROM runs WHERE race_bool=False AND race_id>=0)>0 THEN\n",
    "            UPDATE runs SET race_id=-1 WHERE race_bool=False AND race_id>=0;\n",
    "        END IF;\n",
    "        \n",
    "        RETURN NEW;\n",
    "    END;\n",
    "$race_no_more$ LANGUAGE PLPGSQL;\n",
    "''')\n",
    "\n",
    "rs = con.execute('''\n",
    "DROP TRIGGER IF EXISTS race_no_more on runs;\n",
    "CREATE TRIGGER race_no_more AFTER UPDATE ON runs\n",
    "    FOR EACH ROW EXECUTE FUNCTION race_no_more();\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2023,)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('''SELECT count(runner_id)\n",
    "            FROM runs''').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 'gpx files/Morning Run3', datetime.date(2021, 4, 8), datetime.time(0, 49, 7), 6.01, 8.31, 152.5, 92.6, [-105.128, 40.3757], [-105.125, 40.3776], [[-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756], [- ... (15715 characters truncated) ... 7], [-105.125, 40.3771], [-105.125, 40.3772], [-105.125, 40.3773], [-105.125, 40.3774], [-105.125, 40.3775], [-105.125, 40.3775], [-105.125, 40.3776]], [{'split (mi)': 1.0, 'pace (min/mi)': 8.59, 'hr (bpm)': 146.78, 'gain (m)': 15.8}, {'split (mi)': 2.0, 'pace (min/mi)': 8.71, 'hr (bpm)': 151.22, 'gai ... (275 characters truncated) ...  6.0, 'pace (min/mi)': 8.03, 'hr (bpm)': 151.46, 'gain (m)': -10.6}, {'split (mi)': 0.01, 'pace (min/mi)': 11.3, 'hr (bpm)': 155.67, 'gain (m)': 0.0}], [{'Split': '1st Half', 'HR': 151.23}, {'Split': '2nd Half', 'HR': 153.89}], [{'Split': '1st Half', 'Pace': 8.5}, {'Split': '2nd Half', 'Pace': 8.11}], [{'hr': '140-150', 'percentage': 24.63}, {'hr': '150-160', 'percentage': 61.51}, {'hr': '160-170', 'percentage': 13.86}], [{'pace': '7.0-7.5', 'percentage': 12.72}, {'pace': '7.5-8.0', 'percentage': 31.58}, {'pace': '8.0-8.5', 'percentage': 29.09}, {'pace': '8.5-9.0', 'percentage': 19.88}, {'pace': '9.0-9.5', 'percentage': 6.73}], True, 0),\n",
       " (2, 1, 'gpx files/Morning Run37', datetime.date(2020, 7, 26), datetime.time(0, 25, 19), 2.39, 6.92, 149.52, 49.6, [-105.135, 40.3723], [-105.127, 40.3759], [[-105.135, 40.3723], [-105.135, 40.3723], [-105.135, 40.3723], [-105.135, 40.3723], [-105.135, 40.3723], [-105.135, 40.3723], [-105.135, 40.3723], [- ... (7112 characters truncated) ... 5], [-105.128, 40.3756], [-105.128, 40.3757], [-105.127, 40.3758], [-105.127, 40.3759], [-105.127, 40.3759], [-105.127, 40.3759], [-105.127, 40.3759]], [{'split (mi)': 1.0, 'pace (min/mi)': 5.75, 'hr (bpm)': 145.46, 'gain (m)': 18.0}, {'split (mi)': 2.0, 'pace (min/mi)': 8.19, 'hr (bpm)': 153.12, 'gain (m)': -21.2}, {'split (mi)': 0.39, 'pace (min/mi)': 8.47, 'hr (bpm)': 157.13, 'gain (m)': -5.2}], [{'Split': '1st Half', 'HR': 146.46}, {'Split': '2nd Half', 'HR': 154.24}], [{'Split': '1st Half', 'Pace': 6.01}, {'Split': '2nd Half', 'Pace': 8.31}], [{'hr': '130-140', 'percentage': 6.47}, {'hr': '140-150', 'percentage': 25.88}, {'hr': '150-160', 'percentage': 67.65}], [{'pace': '0.0-0.5', 'percentage': 22.37}, {'pace': '7.0-7.5', 'percentage': 6.91}, {'pace': '7.5-8.0', 'percentage': 18.75}, {'pace': '8.0-8.5', 'percentage': 30.92}, {'pace': '8.5-9.0', 'percentage': 14.8}, {'pace': '9.0-9.5', 'percentage': 6.25}], False, -1),\n",
       " (3, 1, 'gpx files/Morning Run23', datetime.date(2020, 11, 4), datetime.time(0, 44, 15), 5.19, 9.1, 151.07, 78.6, [-105.128, 40.3757], [-105.13, 40.3748], [[-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3756], [-105.128, 40.3755], [-105.128, 40.3755], [- ... (13471 characters truncated) ...  40.3748], [-105.13, 40.3748], [-105.13, 40.3748], [-105.13, 40.3748], [-105.13, 40.3748], [-105.13, 40.3748], [-105.13, 40.3748], [-105.13, 40.3748]], [{'split (mi)': 1.0, 'pace (min/mi)': 8.66, 'hr (bpm)': 141.06, 'gain (m)': 13.8}, {'split (mi)': 2.0, 'pace (min/mi)': 9.73, 'hr (bpm)': 151.92, 'gai ... (193 characters truncated) ... 5.0, 'pace (min/mi)': 10.23, 'hr (bpm)': 155.25, 'gain (m)': -20.4}, {'split (mi)': 0.19, 'pace (min/mi)': 8.63, 'hr (bpm)': 158.1, 'gain (m)': -3.2}], [{'Split': '1st Half', 'HR': 147.49}, {'Split': '2nd Half', 'HR': 154.64}], [{'Split': '1st Half', 'Pace': 9.02}, {'Split': '2nd Half', 'Pace': 9.19}], [{'hr': '140-150', 'percentage': 30.14}, {'hr': '150-160', 'percentage': 62.95}, {'hr': '160-170', 'percentage': 6.91}], [{'pace': '7.5-8.0', 'percentage': 19.34}, {'pace': '8.0-8.5', 'percentage': 39.55}, {'pace': '8.5-9.0', 'percentage': 29.71}, {'pace': '9.0-9.5', 'percentage': 11.4}], True, 2),\n",
       " (4, 1, 'gpx files/Morning Run36', datetime.date(2020, 7, 28), datetime.time(0, 25, 24), 3.01, 8.57, 146.0, 47.8, [-105.128, 40.3758], [-105.128, 40.3756], [[-105.128, 40.3758], [-105.128, 40.3758], [-105.128, 40.3758], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [- ... (7786 characters truncated) ... 5], [-105.128, 40.3755], [-105.128, 40.3755], [-105.128, 40.3755], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756]], [{'split (mi)': 1.0, 'pace (min/mi)': 8.77, 'hr (bpm)': 142.07, 'gain (m)': 11.2}, {'split (mi)': 2.0, 'pace (min/mi)': 8.48, 'hr (bpm)': 142.76, 'gai ... (29 characters truncated) ...  3.0, 'pace (min/mi)': 8.16, 'hr (bpm)': 153.27, 'gain (m)': -14.6}, {'split (mi)': 0.01, 'pace (min/mi)': 15.58, 'hr (bpm)': 160.0, 'gain (m)': 0.0}], [{'Split': '1st Half', 'HR': 140.58}, {'Split': '2nd Half', 'HR': 151.64}], [{'Split': '1st Half', 'Pace': 8.73}, {'Split': '2nd Half', 'Pace': 8.42}], [{'hr': '130-140', 'percentage': 17.88}, {'hr': '140-150', 'percentage': 44.13}, {'hr': '150-160', 'percentage': 37.99}], [{'pace': '7.0-7.5', 'percentage': 6.96}, {'pace': '7.5-8.0', 'percentage': 21.45}, {'pace': '8.0-8.5', 'percentage': 31.48}, {'pace': '8.5-9.0', 'percentage': 22.28}, {'pace': '9.0-9.5', 'percentage': 11.98}, {'pace': '9.5-10.0', 'percentage': 5.85}], True, 4),\n",
       " (5, 1, 'gpx files/Morning Run36', datetime.date(2020, 7, 28), datetime.time(0, 25, 24), 3.01, 8.57, 146.0, 47.8, [-105.128, 40.3758], [-105.128, 40.3756], [[-105.128, 40.3758], [-105.128, 40.3758], [-105.128, 40.3758], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [-105.128, 40.3757], [- ... (7786 characters truncated) ... 5], [-105.128, 40.3755], [-105.128, 40.3755], [-105.128, 40.3755], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756], [-105.128, 40.3756]], [{'split (mi)': 1.0, 'pace (min/mi)': 8.77, 'hr (bpm)': 142.07, 'gain (m)': 11.2}, {'split (mi)': 2.0, 'pace (min/mi)': 8.48, 'hr (bpm)': 142.76, 'gai ... (29 characters truncated) ...  3.0, 'pace (min/mi)': 8.16, 'hr (bpm)': 153.27, 'gain (m)': -14.6}, {'split (mi)': 0.01, 'pace (min/mi)': 15.58, 'hr (bpm)': 160.0, 'gain (m)': 0.0}], [{'Split': '1st Half', 'HR': 140.58}, {'Split': '2nd Half', 'HR': 151.64}], [{'Split': '1st Half', 'Pace': 8.73}, {'Split': '2nd Half', 'Pace': 8.42}], [{'hr': '130-140', 'percentage': 17.88}, {'hr': '140-150', 'percentage': 44.13}, {'hr': '150-160', 'percentage': 37.99}], [{'pace': '7.0-7.5', 'percentage': 6.96}, {'pace': '7.5-8.0', 'percentage': 21.45}, {'pace': '8.0-8.5', 'percentage': 31.48}, {'pace': '8.5-9.0', 'percentage': 22.28}, {'pace': '9.0-9.5', 'percentage': 11.98}, {'pace': '9.5-10.0', 'percentage': 5.85}], False, -1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 5 rows\n",
    "con.execute('''SELECT *\n",
    "            FROM runs\n",
    "            LIMIT 5''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# disconnect from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
